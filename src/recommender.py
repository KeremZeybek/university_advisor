"""
=============================================================================
MODÃœL: Recommendation Engine (HIGH PERFORMANCE VECTORIZED)
DOSYA: src/recommender.py
TANIM: YÃ¼ksek performanslÄ±, vektÃ¶rize edilmiÅŸ Ã¶neri motoru.
       - Numpy/Pandas Vectorization (10x-20x HÄ±z ArtÄ±ÅŸÄ±)
       - Lazy Text Generation (Sadece sonuÃ§lar iÃ§in metin Ã¼retimi)
       - Dinamik AÄŸÄ±rlÄ±klandÄ±rma DesteÄŸi
=============================================================================
"""

import pandas as pd
import numpy as np
import re
import logging
from typing import Dict, List, Set, Tuple, Optional, Any

# Logging Setup
logger = logging.getLogger(__name__)

# ML Engine Import
try:
    from src.ml_engine import calculate_ml_scores
except ImportError:
    try:
        from ml_engine import calculate_ml_scores
    except:
        def calculate_ml_scores(df, kw): 
            logger.warning("ML Engine bulunamadÄ±, 0 score dÃ¶ndÃ¼rÃ¼lÃ¼yor")
            return np.zeros(len(df))

# --- KONFÄ°GÃœRASYON ---
SCORING_WEIGHTS = {
    'graduation_urgency': 1.3,
    'readiness': 1.0,
    'chain_impact': 1.1,
    'scarcity_bonus': 1.0,
    'interest_fit': 0.8,
    'overlap_risk': 0.7,
    'subject_penalty': 1.0,
}

MIN_FINAL_SCORE = 15
MAX_RECOMMENDATIONS = 20

# --- YARDIMCI FONKSÄ°YONLAR ---

def get_adaptive_weights(year: int) -> Dict[str, float]:
    """
    Ã–ÄŸrencinin sÄ±nÄ±fÄ±na gÃ¶re aÄŸÄ±rlÄ±klarÄ± dinamik olarak ayarlar.
    
    MantÄ±k:
    - 1. SÄ±nÄ±f: Zincir aÃ§mak ve keÅŸfetmek Ã¶nemlidir.
    - 4. SÄ±nÄ±f: Mezuniyet her ÅŸeyden Ã¶nemlidir, zincir aÃ§manÄ±n anlamÄ± yoktur.
    """
    weights = SCORING_WEIGHTS.copy()
    
    if year >= 4:
        # Son SÄ±nÄ±f Modu (Panic Mode): Sadece mezun olmaya odaklan
        weights['graduation_urgency'] = 2.5  # Ã‡ok bÃ¼yÃ¼k Ã¶ncelik
        weights['chain_impact'] = 0.1        # Zincir aÃ§manÄ±n artÄ±k faydasÄ± yok
        weights['interest_fit'] = 0.5        # SeÃ§icilik lÃ¼ksÃ¼ azalÄ±r
        weights['scarcity_bonus'] = 1.5      # KaÃ§Ä±rÄ±rsan okul uzar
        logger.info("Adaptive Weights: 4. SÄ±nÄ±f (Mezuniyet OdaklÄ±) profili uygulandÄ±.")
        
    elif year == 3:
        # 3. SÄ±nÄ±f Modu: Denge
        weights['graduation_urgency'] = 1.5
        # Standart aÄŸÄ±rlÄ±klar korunur
        logger.info("Adaptive Weights: 3. SÄ±nÄ±f (Dengeli) profili uygulandÄ±.")
        
    elif year <= 2:
        # 1. ve 2. SÄ±nÄ±f Modu (Exploration Mode): GeleceÄŸi planla
        weights['graduation_urgency'] = 1.0  # HenÃ¼z panik yok
        weights['chain_impact'] = 1.6        # Gelecek kilitleri aÃ§mak Ã§ok Ã¶nemli
        weights['interest_fit'] = 1.2        # Ä°lgi alanÄ±nÄ± keÅŸfet
        logger.info("Adaptive Weights: Alt SÄ±nÄ±f (KeÅŸif ve Zincir) profili uygulandÄ±.")
        
    return weights

def extract_codes(text: str) -> List[str]:
    if not isinstance(text, str): return []
    return re.findall(r"([A-Z]{2,5}\s+\d{3,4})", text)

def normalize_keywords(keywords: Any) -> Set[str]:
    if isinstance(keywords, dict):
        return set(kw.lower() for kw in keywords.keys())
    elif isinstance(keywords, (list, tuple)):
        return set(str(kw).lower() for kw in keywords)
    elif isinstance(keywords, str):
        return set(keywords.lower().split())
    else:
        return set()

def extract_course_level(code: str) -> int:
    try:
        # HÄ±zlÄ± split
        return (int(code.split()[1]) // 100) * 100
    except:
        return 0

def check_prerequisites(prereq_text: str, taken_courses: Set[str]) -> bool:
    """
    SatÄ±r bazlÄ± Ã§alÄ±ÅŸmak zorunda olan nadir fonksiyonlardan.
    Ancak sonucu boolean dÃ¶ner, hÄ±zdan tasarruf iÃ§in apply iÃ§inde sadece bunu Ã§aÄŸÄ±rÄ±rÄ±z.
    """
    if pd.isna(prereq_text) or str(prereq_text).lower() in ["nan", "none", "", " "]:
        return True

    text = str(prereq_text).upper()
    text = re.sub(r'MINIMUM GRADE OF [A-Z]', '', text)
    text = re.sub(r'LEVEL \d+', '', text)
    
    req_blocks = text.split(' AND ')
    
    for block in req_blocks:
        options = block.split(' OR ')
        satisfied = False
        for option in options:
            found = extract_codes(option)
            if not found: continue
            # EÄŸer opsiyondaki herhangi bir ders alÄ±ndÄ±ysa bu blok tamamdÄ±r
            if any(c in taken_courses for c in found):
                satisfied = True
                break
        
        if not satisfied:
            # HiÃ§bir opsiyon saÄŸlanmadÄ±ysa Ã¶n koÅŸul tutmuyor
            # (found boÅŸsa yani ders kodu yoksa text aÃ§Ä±klamadÄ±r, pass geÃ§iyoruz)
            if any(extract_codes(block)):
                return False
            
    return True

def analyze_student_profile(transcript_set, catalog_df):
    """
    Ã–ÄŸrencinin aldÄ±ÄŸÄ± derslere bakarak ilgi alanlarÄ±nÄ± (Keyword) Ã§Ä±karÄ±r.
    Ã–rn: 'Machine Learning', 'Computer Vision' aldÄ±ysa -> ['LEARNING', 'VISION', 'COMPUTER'] Ã§Ä±karÄ±r.
    """
    if not transcript_set or catalog_df.empty:
        return []

    # Analiz edilmeyecek gereksiz kelimeler (Stopwords)
    STOPWORDS = {
        'INTRODUCTION', 'TO', 'OF', 'THE', 'AND', 'IN', 'FOR', 'WITH', 
        'I', 'II', 'III', 'IV', 'V', 'PROJECT', 'DESIGN', 'ANALYSIS', 
        'APPLICATION', 'APPLICATIONS', 'BASIC', 'GENERAL', 'PRINCIPLES',
        'FUNDAMENTALS', 'TOPICS', 'ADVANCED', 'SYSTEMS', 'THEORY', 'PRACTICE',
        'ENGINEERING', 'SCIENCE', 'SOCIAL', 'TERM', 'GRADUATION', 'SUMMER',
        'STUDIES', 'CONTEMPORARY', 'ISSUES', 'METHODS'
    }

    # Transkriptteki derslerin satÄ±rlarÄ±nÄ± bul
    taken_courses = catalog_df[catalog_df['Course Code'].isin(transcript_set)]
    
    word_counter = {}
    
    for _, row in taken_courses.iterrows():
        # Ders adÄ±nÄ± kelimelere bÃ¶l
        course_name = str(row['Course Name']).upper()
        # Sadece harflerden oluÅŸan en az 3 harfli kelimeleri al
        words = re.findall(r'\b[A-Z]{3,}\b', course_name)
        
        for w in words:
            if w not in STOPWORDS:
                word_counter[w] = word_counter.get(w, 0) + 1

    # En Ã§ok tekrar eden kelimeleri sÄ±rala
    sorted_words = sorted(word_counter.items(), key=lambda x: x[1], reverse=True)
    
    # En gÃ¼Ã§lÃ¼ 5 ilgi alanÄ±nÄ± al
    profile_keywords = [w[0] for w in sorted_words[:5]]
    
    logger.info(f"Profil Analizi Sonucu: {profile_keywords}")
    return profile_keywords

def build_chain_map(df: pd.DataFrame) -> Dict[str, int]:
    chain_map = {code: 0 for code in df['Course Code']}
    for prereq_text in df.get('Prerequisites', []):
        if pd.isna(prereq_text): continue
        found = extract_codes(str(prereq_text).upper())
        for code in found:
            if code in chain_map:
                chain_map[code] += 1
    return chain_map

def calculate_subject_penalty_map(prefixes: np.ndarray, keywords: Any) -> Dict[str, int]:
    """Her benzersiz prefix iÃ§in cezayÄ± bir kez hesapla"""
    kw_tokens = normalize_keywords(keywords)
    penalty_map = {}
    
    if not kw_tokens:
        return {p: 0 for p in prefixes}

    for p in prefixes:
        p_lower = p.lower()
        if p_lower in kw_tokens:
            penalty_map[p] = 0
        else:
            # KÄ±smi uyum kontrolÃ¼
            match = False
            for kw in kw_tokens:
                if p_lower.startswith(kw[:2]) or kw.startswith(p_lower[:2]):
                    penalty_map[p] = 5
                    match = True
                    break
            if not match:
                penalty_map[p] = 25
                
    return penalty_map

# --- STRING GENERATORS (SADECE SONUÃ‡LAR Ä°Ã‡Ä°N Ã‡ALIÅIR) ---

def generate_explanation(row) -> str:
    reasons = []
    
    # Skorlar DataFrame'den gelir
    gus = row.get('GUS', 0)
    cis = row.get('CIS', 0)
    csb = row.get('CSB', 0)
    ifs = row.get('IFS', 0)
    srp = row.get('SRP', 0)
    base_ai = row.get('AI_Score', 0)
    
    if gus >= 40: reasons.append("ğŸ”´ Mezuniyet ÅartÄ±")
    elif gus >= 35: reasons.append("ğŸŸ  Ãœniversite ÅartÄ±")
    elif gus >= 25: reasons.append("ğŸ”µ Ã‡ekirdek Ders")
    elif gus >= 15: reasons.append("ğŸŸ¡ Alan Dersi")
    
    if cis > 0: reasons.append(f"ğŸ”— {int(row.get('Chain_Size', 0))} dersin Ã¶nÃ¼nÃ¼ aÃ§Ä±yor")
    if csb > 0: reasons.append("â° Sadece bu dÃ¶nem aÃ§Ä±lÄ±yor")
    if ifs > 5: reasons.append(f"â¤ï¸ Ä°lgi alanÄ± uyumu (%{int(base_ai)})")
    if srp > 0: reasons.append("âš ï¸ Alan DÄ±ÅŸÄ±")
    
    # Level kontrolÃ¼
    lvl = row.get('Level_Num', 0)
    year = row.get('Student_Year', 1)
    if lvl < year * 100: reasons.append("ğŸ“‰ Alttan Ders")
    
    return " | ".join(reasons) if reasons else "Serbest SeÃ§meli"

def generate_category(row) -> str:
    srp = row.get('SRP', 0)
    if srp > 100: return "ğŸš« Alan DÄ±ÅŸÄ±"
    
    gus = row.get('GUS', 0)
    ifs = row.get('IFS', 0)
    cis = row.get('CIS', 0)
    
    # GUS PuanlarÄ±na gÃ¶re kategori (graduation_urgency_score fonksiyonundaki mantÄ±kla eÅŸleÅŸmeli)
    if gus >= 40: return "ğŸ”´ Kritik Zorunlu"     # Required
    if gus >= 35: return "ğŸŸ  Ãœniversite ÅartÄ±"   # University
    if gus >= 25:                                # Core
        return "ğŸŸ¢ Ã‡ekirdek & Ä°lgi AlanÄ±" if ifs >= 5 else "ğŸ”µ Ã‡ekirdek (Core)"
    if gus >= 15:                                # Area
        return "ğŸŸ¢ Alan & Ä°lgi AlanÄ±" if ifs >= 5 else "ğŸŸ¡ Alan (Area)"
        
    if cis >= 5: return "ğŸŸ£ Stratejik (Zincir)"
    if ifs >= 5: return "ğŸŸ¢ Ä°lgi AlanÄ±"
    
    return "âšª Genel SeÃ§meli"


# --- ANA MOTOR (VEKTÃ–RÄ°ZE) ---

def get_recommendations(
    catalog_df: pd.DataFrame,
    student_params: Dict[str, Any],
    audit_data: Dict[str, Any],
    keywords: Any,
    weights: Optional[Dict[str, float]] = None,
    min_score: int = MIN_FINAL_SCORE,
    max_recs: int = MAX_RECOMMENDATIONS
) -> pd.DataFrame:
    
    year = student_params.get('year', 1)
    if weights is None:
        weights = get_adaptive_weights(year)
    
    # --- 1. HIZLI FÄ°LTRELEME ---
    df = catalog_df.copy().reset_index(drop=True)
    taken_set = set(student_params.get('taken', []))
    year = student_params.get('year', 1)
    
    # AlÄ±nanlarÄ± Ã§Ä±kar
    df = df[~df['Course Code'].isin(taken_set)]
    # Lab/Recit/Discussion Ã§Ä±kar (Regex yerine str methodlarÄ± daha hÄ±zlÄ± olabilir ama regex esnektir)
    df = df[~df['Course Code'].str.contains(r"\d{3}[RLD]$", regex=True)]
    
    # Lisans / YL Filtresi
    # Level sÃ¼tunu yoksa oluÅŸtur, varsa kullan
    if 'Level' not in df.columns:
        df['Level'] = df['Course Code'].apply(extract_course_level)
    
    if student_params.get('level') == "Lisans":
        df = df[df['Level'] < 500]
    else:
        df = df[df['Level'] >= 400]
        
    df = df.reset_index(drop=True)
    
    # --- 2. Ã–N KOÅUL (Tek YavaÅŸ KÄ±sÄ±m - Apply Mecbur) ---
    if 'Prerequisites' in df.columns:
        # Sadece dolu olanlarÄ± kontrol et
        mask_has_prereq = df['Prerequisites'].notna() & (df['Prerequisites'] != "")
        # VektÃ¶rize edilemediÄŸi iÃ§in apply kullanÄ±yoruz ama sadece gerekli satÄ±rlara
        valid_prereqs = df.loc[mask_has_prereq, 'Prerequisites'].apply(
            lambda x: check_prerequisites(x, taken_set)
        )
        # Ã–n koÅŸulu olmayanlar (True) + Ã–n koÅŸulu saÄŸlayanlar
        df = df[~mask_has_prereq | valid_prereqs].reset_index(drop=True)
    
    if df.empty: return pd.DataFrame()

    # --- 3. VERÄ° HAZIRLIÄI (SÃœTUN BAZLI) ---
    
    # Level Num (Hesaplama iÃ§in int hali)
    # df['Level'] zaten var ama emin olalÄ±m
    df['Level_Num'] = (df['Level'] // 100) * 100
    
    # AI Score
    if keywords:
        df['AI_Score'] = calculate_ml_scores(df, keywords)
    else:
        df['AI_Score'] = 0.0
        
    # Prereq Count (Metinden sayma)
    def fast_count_prereqs(x):
        if pd.isna(x): return 0
        return len(extract_codes(str(x)))
    df['Prereq_Count'] = df['Prerequisites'].apply(fast_count_prereqs)
    
    # Chain Map
    chain_map = build_chain_map(df)
    df['Chain_Size'] = df['Course Code'].map(chain_map).fillna(0).astype(int)
    
    # Prefix Counts
    df['Prefix'] = df['Course Code'].str.split().str[0]
    prefix_counts = df['Prefix'].value_counts()
    df['Prefix_Count'] = df['Prefix'].map(prefix_counts).fillna(1).astype(int)
    
    # Opening Terms (VarsayÄ±lan 2)
    if 'Opening_Terms' not in df.columns:
        df['Opening_Terms'] = 2
    
    # Set KÃ¼meleri (Boolean Maskeler)
    required = audit_data.get('required', set())
    university = audit_data.get('university', set())
    core = audit_data.get('core', set())
    area = audit_data.get('area', set())
    
    is_required = df['Course Code'].isin(required)
    is_university = df['Course Code'].isin(university)
    is_core = df['Course Code'].isin(core)
    is_area = df['Course Code'].isin(area)
    is_critical = is_required | is_university
    is_elective = is_core | is_area

    # --- 4. VEKTÃ–RÄ°ZE PUANLAMA (NUMPY/PANDAS ILE HIZLI HESAP) ---
    
    # 1. Graduation Urgency Score (GUS)
    # np.select condlist sÄ±rasÄ±yla kontrol edilir, ilk True olanÄ±n deÄŸerini alÄ±r
    df['GUS'] = np.select(
        [is_required, is_university, is_core, is_area],
        [40, 35, 25, 15],
        default=0
    )
    
    # 2. Readiness Score (RES)
    # Level farkÄ±
    level_diff = (df['Level_Num'] // 100) - year
    base_res = 20
    
    level_adj = np.select(
        [level_diff == 0, level_diff == 1, level_diff >= 2, level_diff < 0],
        [10, 5, -15, -5],
        default=0
    )
    
    prereq_adj = np.select(
        [df['Prereq_Count'] == 0, df['Prereq_Count'] >= 3],
        [5, -10],
        default=0
    )
    
    df['RES'] = np.maximum(base_res + level_adj + prereq_adj, 0)
    
    # 3. Chain Impact Score (CIS)
    df['CIS'] = np.select(
        [df['Chain_Size'] >= 3, df['Chain_Size'] == 2, df['Chain_Size'] == 1],
        [20, 12, 5],
        default=0
    )
    
    # 4. Scarcity Bonus (CSB)
    # Sadece 1 dÃ¶nem aÃ§Ä±lanlara bonus
    scarcity_mask = (df['Opening_Terms'] == 1)
    base_bonus = 5
    critical_bonus = np.where(is_critical, 10, 0)
    chain_bonus = np.where(df['Chain_Size'] > 0, 5, 0)
    
    df['CSB'] = np.where(scarcity_mask, base_bonus + critical_bonus + chain_bonus, 0)
    
    # 5. Interest Fit Score (IFS)
    # Elective ise %40, deÄŸilse %20. Max 20 veya 10.
    # AI_Score genelde 0-100 arasÄ±dÄ±r.
    elective_score = np.minimum(df['AI_Score'] * 0.4, 20)
    mandatory_score = np.minimum(df['AI_Score'] * 0.2, 10)
    df['IFS'] = np.where(is_elective, elective_score, mandatory_score).astype(int)
    
    # 6. Overlap Risk Score (ORS)
    df['ORS'] = np.select(
        [df['Prefix_Count'] >= 4, df['Prefix_Count'] == 3],
        [15, 8],
        default=0
    )
    
    # 7. Subject Relevance Penalty (SRP)
    # Kritik derslerde (GUS > 0) ceza uygulanmaz
    unique_prefixes = df['Prefix'].unique()
    penalty_map = calculate_subject_penalty_map(unique_prefixes, keywords)
    raw_srp = df['Prefix'].map(penalty_map).fillna(0)
    df['SRP'] = np.where(df['GUS'] > 0, 0, raw_srp)
    
    # --- 5. FÄ°NAL SKOR VE SIRALAMA ---
    
    df['Final_Score'] = (
        (df['GUS'] * weights['graduation_urgency']) +
        (df['RES'] * weights['readiness']) +
        (df['CIS'] * weights['chain_impact']) +
        (df['CSB'] * weights['scarcity_bonus']) +
        (df['IFS'] * weights['interest_fit']) -
        (df['ORS'] * weights['overlap_risk']) -
        (df['SRP'] * weights['subject_penalty'])
    )
    
    # Negatifleri sÄ±fÄ±rla
    df['Final_Score'] = df['Final_Score'].clip(lower=0)
    
    # Filtrele ve SÄ±rala (EN Ã–NEMLÄ° PERFORMANS ADIMI)
    # TÃ¼m tabloya metin Ã¼retmek yerine, Ã¶nce eliyoruz.
    result_df = df[df['Final_Score'] > min_score].sort_values(
        by='Final_Score', ascending=False
    ).head(max_recs).copy()
    
    if result_df.empty:
        return pd.DataFrame(columns=['Course Code', 'Course Name', 'Final_Score', 'Category', 'Explanation'])

    # --- 6. METÄ°N ÃœRETÄ°MÄ° (LAZY GENERATION) ---
    # Sadece seÃ§ilen az sayÄ±daki ders iÃ§in Ã§alÄ±ÅŸÄ±r
    result_df['Student_Year'] = year
    result_df['Category'] = result_df.apply(generate_category, axis=1)
    result_df['Explanation'] = result_df.apply(generate_explanation, axis=1)
    
    return result_df


def get_recommendations_with_stats(
    catalog_df: pd.DataFrame,
    student_params: Dict[str, Any],
    audit_data: Dict[str, Any],
    keywords: Any
) -> Tuple[pd.DataFrame, Dict[str, Any]]:
    
    result = get_recommendations(catalog_df, student_params, audit_data, keywords)
    
    stats = {
        'total_recommended': len(result),
        'by_category': result['Category'].value_counts().to_dict() if not result.empty else {},
        'avg_score': float(result['Final_Score'].mean()) if not result.empty else 0,
        'max_score': float(result['Final_Score'].max()) if not result.empty else 0,
        'min_score': float(result['Final_Score'].min()) if not result.empty else 0,
        'top_5_courses': result[['Course Code', 'Course Name', 'Final_Score']].head(5).to_dict('records') if not result.empty else [],
    }
    
    return result, stats